\documentclass{article}

\usepackage{amssymb}
\usepackage{float}
\usepackage[utf8]{inputenc}
\usepackage[english,ukrainian]{babel}
\usepackage{array}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepgfplotslibrary{statistics}
\usepackage{tikz}
\graphicspath{ {./images/} }
\setcounter{section}{-1}
\newtheorem{theorem}{Теорема}
\usepackage{biblatex}

\title{Розрахункова Робота 2 \\
        з математичної статистики\\ 
        Варіант 133}
\author{Воробйов Георгій}
\begin{document}

\maketitle

\tableofcontents

\section{Завдання}
\begin{enumerate}
    \item Проведiть первинний аналiз вибiрки. Це включає статистичний ряд (для розподiлiв —
        iнтервальний), емпiричну функцiю розподiлу (для неперервних розподiлiв iнтервальну), її
        графiк, полiгон частот (для дискретних розподiлiв), гiстограму (неперервнихрозподiлiв), box-and-whisker 
        plot.
    \item Знайдiть вибiркове середнє, вибiркову дисперсiю, виправлену вибiркову дисперсiю, вибiркову
        медiану, вибiркову моду, вибiрковi коефiцiєнти асиметрiї та ексцесу.
    \item Обґрунтуйтета висуньте (нову) гiпотезу про розподiл генеральної сукупностi. 
    \item Методом моментiв та методом максимальної вiрогiдностi знайдiть оцiнки параметрiв
        розподiлу. В деяких випадках це може бути не дуже просто (як, наприклад, для
        параметра N бiномiальної генеральної сукупностi). Це чудовий спосiб проявити креативнiсть
        та/або вмiння користуватися Google.
    \item Для кожного параметра кращу з цих двох оцiнок перевiрте на (асимптотичну)незмiщенiсть, консистентнiсть 
        та ефективнiсть.
    \item Побудуйте довiрчi iнтервали надiйнiстю 0.95 для параметрiв розподiлу.
    \item Нарештi, перевiрте висунуту гiпотезу про розподiл генеральної сукупностi за
        допомогою критерiю $\chi^2$
    \item Проявiть всi свої лiтературнi здiбностi та напишiть висновки
\end{enumerate}
Задана вибірка: \\ 
2  1  1  4  4  3  4  3  2  7  6  1  5  3  3  1  4  3  2  3  2  3  2  3  4 5  3  5  5  1  2  3  6  3
5  5  2  5  2  2  0  3  0  2  6  2  3  4  3  2 4  1  4  3  4  2  4  1  4  5  5  3  3  3  2  4  3  2
4  3  3  3  3  4  2 3  6  1  2  3  3  4  0  3  5  1  4  4  3  3  1  3  3  6  2  2  3  2  5  3 
\section{Розв'язок}
\subsection{Вступ}
Запишемо відсортовану вибірку: \\
0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 7
\subsection{Аналіз вибірки}
Побудуємо статистичний ряд даної вибірки
\begin{center}
    \begin{tabular}{|c||m{2cm}|m{2cm}|m{2cm}|m{2cm}|}
        \hline
        елементи & Частота $n_i$ & Кумулятивна частота $n^*_i$ & Відносна частота $\nu_i$ & Відносна
        кумулятивна частота $\nu^*_i$ \\
        \hline \hline
        0 & 3  & 3   & 0.03 & 0.03 \\
        \hline
        1 & 10 & 13  & 0.1  & 0.13 \\
        \hline
        2 & 20 & 33  & 0.2  & 0.33 \\
        \hline
        3 & 33 & 66  & 0.33 & 0.66 \\
        \hline
        4 & 17 & 83  & 0.17 & 0.83 \\
        \hline
        5 & 11 & 94  & 0.11 & 0.94 \\
        \hline
        6 & 5  & 99  & 0.05 & 0.99 \\
        \hline
        7 & 1  & 100 & 1   & 1 \\
        \hline
    \end{tabular}
    
\end{center}
\newpage
За даними таблиці можемо побудувати полігон відносних частот та емпіричну функцію розподілу 
\begin{figure}[H]
    \centering
    \caption{Полігон частот}
    \begin{tikzpicture}[scale=1.5]
        \begin{axis}[
                xmin= -0.1,
                xmax= 7.1,
                ymin=0,
                ymax=0.35,
                axis lines = left,
                xmajorgrids=true,
                ymajorgrids=true,
                grid style=dashed,
                ytick = {0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35},
            ]
            
            \addplot[
                color=blue,
            ]
            coordinates{
                (0, 0.03)(1, 0.1)(2, 0.2)(3, 0.33)(4, 0.17)(5, 0.11)(6, 0.05)(7, 0.01)
            };

        \end{axis}
    \end{tikzpicture}
\end{figure}
Маємо наступну емпіричну функцію розподілу
$$F^*_n(x) =
\begin{cases}
    0    & x \leq 0 \\
    0.03 & 0 < x \leq 1 \\
    0.13 & 1 < x \leq 2 \\
    0.33 & 2 < x \leq 3 \\
    0.66 & 3 < x \leq 4 \\
    0.83 & 4 < x \leq 5 \\
    0.94 & 5 < x \leq 6 \\
    0.99 & 6 < x \leq 7 \\
    1    & x > 7 \\
\end{cases}
    $$
Відповідний їй графік:
\begin{figure}[H]
    \centering
    \caption{Епірична функція розподілу}
    
    \begin{tikzpicture}[scale=1.5]
        \begin{axis}[
                xmin= -0.5,
                xmax= 7.5,
                ymin=-0.1,
                ymax=1.1,
                axis lines = left,
                xmajorgrids=true,
                ymajorgrids=true,
                grid style=dashed,
                xtick={0, 1, 2, 3, 4, 5, 6, 7}
            ]
            
            \addplot[domain=-1:0, color=blue, <-] (x, 0);
            \addplot[domain=0:0.03, dashed, color=black,] (0, x);
            
            \addplot[domain=0:1, color=blue,<-] (x, 0.03);
            \addplot[domain=0.03:0.13, dashed, color=black,] (1, x);
            
            \addplot[domain=1:2, color=blue,<-] (x, 0.13);
            \addplot[domain=0.13:0.33, dashed, color=black,] (2, x);


            \addplot[domain=2:3, color=blue,<-] (x, 0.33);
            \addplot[domain=0.33:0.66, dashed, color=black,] (3, x);

            \addplot[domain=3:4, color=blue,<-] (x, 0.66);
            \addplot[domain=0.66:0.83, dashed, color=black,] (4, x);

            \addplot[domain=4:5, color=blue,<-] (x, 0.83);
            \addplot[domain=0.83:0.94, dashed, color=black,] (5, x);

            \addplot[domain=5:6, color=blue,<-] (x, 0.94);
            \addplot[domain=0.94:0.99, dashed, color=black,] (6, x);

            \addplot[domain=6:7, color=blue,<-] (x, 0.99);
            \addplot[domain=0.99:1, dashed, color=black,] (7, x);

            \addplot[domain=7:8, color=blue,<-] (x, 1);
        \end{axis}
    \end{tikzpicture}
\end{figure}
\begin{figure}[H]
    \centering
    \caption{Box and whisker plot}
    
    \begin{tikzpicture}[scale=1.5]
        \begin{axis}[
                xmin= -0.4,
                xmax= 7.4,
                ymin = 0,
                ymax = 2,
                axis lines = left,
                xtick={0, 1, 2, 3, 4, 5, 6, 7},
                ytick=\empty,
            ]
            
            \addplot+[
                boxplot prepared={
                    median = 3,
                    upper quartile = 4,
                    lower quartile = 2,
                    upper whisker = 7,
                    lower whisker = 0,
                },
            ]
            coordinates {};
        \end{axis}
    \end{tikzpicture}
\end{figure}
\newpage
\subsection{Вибіркові статистики}
Порахуємо значення вибіркового середнього:
$$\overline{\xi}=\frac{1}{n}\sum_{i=1}^{100} \xi_i$$

$$\overline{\xi}_{\textrm{Знач}}  = 3.09$$
Порахуємо значення вибіркової дисперсії:
$$\mathbb{D}^{**}=\frac{1}{n} \sum_{i=1}^{100} (\xi_i - \overline{\xi})^2$$
$$\mathbb{D}^{**}\xi_{\textrm{Знач}} = 2.08$$
Порахуємо значення виправленої вибіркової дисперсії:
$$\mathbb{D}^{***}=\frac{n}{n-1}\mathbb{D}^{**}$$
$$\mathbb{D}^{***}\xi_{\textrm{Знач}} = 2.1$$
Порахуємо вибіркову медіану:
$$Me^*\xi_{\textrm{Знач}}= \left<\text{cередина вибірки}\right> = 3$$
Порахуємо вибіркову моду - значення вибірки, що зустрічається найчастіше: 
$$Mo^*\xi = 3$$
Для розрахунку вибіркових коефіцієнтів асиметрії та ексцесу розрахуємо потрібні початкові та
центральні вибіркові моменти

$$As^* \xi = \frac{\mu_3^*}{({\sigma^*})^3}$$

$$Ex^* \xi = \frac{\mu_4^*}{({\sigma^*})^4} - 3$$

$$\mu_3^* = \mathbb{E}\left[ \xi - \overline{\xi}\right]^3 = 0.667$$

$$(\mu_3^*)_{\textrm{Знач}} =  0.667$$

$$\mu_4^* = \mathbb{E}\left[ \xi - \overline{\xi}\right]^4 = 12.429$$

$$(\mu_4^*)_{\textrm{Знач}} = 12.429$$

$$\sigma^* = \sqrt{\mathbb{D}^{**}} = 1.443$$

$$\sigma^*_{\textrm{Знач}} = 1.443$$

$$As^*\xi_{\textrm{Знач}} = 0.221$$

$$Ex^*\xi_{\textrm{Знач}} = -0.14$$

\newpage
\subsection{Висунення Гіпотези}
\begin{enumerate}
    \item Маємо дискретну ГС
    \item Значення дисперсії менше ніж математичного сподівання(Що схоже на npq та np відповідно)
    \item Має вибіркову медіану рівну вибірковій моді
\end{enumerate}
Тож можемо припустити, що данна ГС є розподіленою біноміально \\ $\xi \sim Bin(N, p)$

\begin{figure}[H]
    \centering
    \caption{Полігон частот}
    \begin{tikzpicture}[scale=1.5]
        \begin{axis}[
                xmin= -0.1,
                xmax= 7.1,
                ymin=0,
                ymax=0.35,
                axis lines = left,
                xmajorgrids=true,
                ymajorgrids=true,
                grid style=dashed,
                ytick = {0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35},
                legend entries = {$data$\\$Bin(9, 0.32)$\\}
            ]
            
            \addplot[
                color=blue,
            ]
            coordinates{
                (0, 0.03)(1, 0.1)(2, 0.2)(3, 0.33)(4, 0.17)(5, 0.11)(6, 0.05)(7, 0.01)
            };
            \addplot[
                color=red,
            ]
            coordinates{
                (0, 0.02)(1, 0.1)(2, 0.22)(3, 0.27)(4, 0.21)(5, 0.11)(6, 0.04)(7, 0.01)
            };

        \end{axis}
    \end{tikzpicture}
\end{figure}
\newpage
\subsection{Оцінки параметра розподілу}
Оцінка параметрів біноміального розподілу при невідомих N і p є дуже складною задачею.
По-перше зазначимо наступну теорему(без доведення)
\begin{theorem}
    Нехай $\xi_1, \dots, \xi_n$ є вибіркою з Генеральної сукупності, розподіленої за біноміальним
    законом, з невідомими значеннями n та p. Тоді
    \begin{enumerate}
        \item Якщо $g(n)$ є неконстантною функцією, то не існує незміщенної оцінки $g(n)$ 
        \item Якщо $g(p)$ є такою, що в околі точки 0 існує $g'(p)$ таким чином, що
            $\lim_{p\rightarrow 0} g'(p)$ не дорівнює нулю або нескінченності. Тоді не існує
            незміщенної оцінки $g(p)$.
    \end{enumerate}
\end{theorem}
Це означає, що не можливо знайти незміщену оцінку параметра n та p.
Фішер не вважав значною проблему пошуку оцінки n, вважаючи, що достатньо оцінки $\max\xi_i$, але,
як показують досліди, для отримання навіть $P\left\{\max\xi_i \geq \frac{N}{2}\right\}\geq 0.5$
потрібна вибірка розміром приблизно $31 500$ для реальних значень параметрів $n=100$, $p=0.3$ 

\subsubsection{Метод моментів}
Маємо відомі нам значення матсподівання та дисперсії:
$$
\begin{cases}
    \mathbb{E}\xi=Np \\
    \mathbb{D}\xi=Np(1-p)\\
\end{cases}
$$
Звідси, підставивши значення $\mathbb{E}^*\xi = \overline{\xi}$ та $D^{***}$ можемо виразити
значення N* та p* :
$$
\begin{cases}
    1-p^* = \frac{\mathbb{D}^{***}\xi}{\overline{\xi}}\\
    \overline{\xi} = N^*p^*
\end{cases}
$$
$$
\begin{cases}
    p^* = \frac{\overline{\xi} - \mathbb{D}^{***}\xi}{\overline{\xi}}\\
    \overline{\xi} = N^*p^*
\end{cases}
$$

$$
\begin{cases}
    p^* = \frac{\overline{\xi} - \mathbb{D}^{***}\xi}{\overline{\xi}}\\
    N^* = \frac{\overline{\xi}^2}{\overline{\xi} - \mathbb{D}^{***}\xi}
\end{cases}
$$
Для значення нашої вибірки отримуємо значення $p^*$ та $N^*$
$$
\begin{cases}
    p^* = \frac{3.09 - 2.1}{3.09} \\
    N^* = \frac{3.09^2}{3.09 - 2.1} 
\end{cases}
$$

$$
\begin{cases}
    p^* = 0.32 \\ 
    N^* = 9.64 
\end{cases}
$$

\subsubsection{Метод максимальної правдоподібності}
Запишемо функцію Правдоподібності
$$
\mathcal{L}(\overrightarrow{x}, N, p) = \prod_{i=1}^{n} \mathbb{P} \{ \xi=x_i \} =  \prod_{i=1}^{n}
C_N^{x_i} p^{x_i} (1-p)^{N-x_i}
$$

$$
\ln\mathcal{L}(\overrightarrow{x}, N, p) = \sum_{i=1}^n lnC_N^{x_k} + \ln p \sum_{i=1}^n x_k +
\ln(1-p)\left( nN -  \sum_{i=1}^n x_k \right)
$$
Так як ми не можемо за допомогою даного методу оцінити значення параметра N, бо $C_N^k$ не є
неперервною функцією, оцінимо лише параметр $p$.
$$
\frac{\partial \ln\mathcal{L}}{\partial p} = \frac{1}{p} \sum_{i=1}^n x_k - \frac{1}{1-p} \left(nN -
\sum_{i=1}^n x_k\right)
$$
Прирівнюючи до нуля знайдемо оцінку p.
$$
(\frac{1}{p^*}+ \frac{1}{1-p^*})\sum_{i=1}^n x_k = \frac{nN}{1-p^*}
$$
$$
\frac{1}{p^*(1-p^*)} \sum_{i=1}^n x_k = \frac{nN}{1-p^*}
$$

$$
p^* = \frac{\sum_{i=1}^n x_k}{nN} = \frac{\overline{x}}{N}
$$

Як бачимо, для оцінки p методом максимальної правдоподібності, ми повинні знайти значення N. Для
цього розглянемо інші оцінки.
\subsubsection{Інші методи оцінки параметру}
\paragraph{Інший метод моментів}
Розглянемо метод моментів, який вигористовує $\max{\xi_i}, \overline\xi, \mathbb{D}^{***}\xi$.
Розглянемо наступну рівність:
$$
N = \frac{N^{\alpha + 1} (Npq)^{\alpha}}{(Np)^\alpha (Np)^\alpha}
$$
Підставивши у якості n будь-яку оцінку, наприклад $\max\xi_i$, а у якості $Np$ - значення
матсподівання, $Npq = \mathbb{D}^{***}\xi$
$$
N^*=\frac{(\max\xi_i)^{\alpha+1}(\mathbb{D}^{***}\xi)^\alpha}{{\overline{\xi}}^\alpha(\max\xi_i -
\overline\xi)^\alpha}
$$
Параметр $\alpha$ вибирається самостійно експериментатором, у \cite{1} показано, що одним із найкращих
значень є $ \alpha = 1 $, для нього маємо оцінку, яку і порахуємо:
$$
N^* = \frac{(\max\xi_i)^2(\mathbb{D}^{***}\xi)}{{\overline{\xi}}(\max\xi_i -
\overline\xi)}
$$
$$
N^*_{\textrm{Знач}} = \frac{7^2 (2.1)}{3.09(7 - 3.09)} = 8.52 
$$
\paragraph{Оцінка Керолла-Ломбарда}
Інша оцінка, яку називають оцінкою Керолла-Ломбарда, є наступна оцінка, яка виводиться з методу
максимальної правдоподібності: \\
У цьому методі ми припускаємо, що $p$ розподілений за бета розподілом з деякимии параметрами $(a,
b)$, тоді ми можемо записати функцію правдоподібності
$$
L(N) = \prod_{i=1}^{k} C_N^{x_i} \left[ (nN + a + b + 1) C_{nN + a + b}^{a + \sum_{j=1}^nx_j }
\right]^{-1}
$$
Дана функція може бути оцінена лише на основі даних, що в нас є, тобто мінімізуємо ї пошуком
локальних мінімумів за означенням локального мінімуму.

\paragraph{Покращена оцінка за допомогою максимума}
Останній метод полягає у тому, що ми додаємо деяке значення, яке визначається за допомогою іншої
оцінки:
$$
N^{**} = \max\xi_i + \sum_{i=0}^{N^* - 2}F_{i+1, N^* - i}^{-1} \left(\frac{1}{n}\right)
$$
Де $F_{u, v}(x)$ - фукнція розподілу $Beta(u, v)$. \\
виведення цієї оцінки розглянуто в \cite{1}.

\subsection{Перевірка параметра на незміщенність, консистентність, ефективність.}
\paragraph{Незміщенність}
Перевіримо на незміщенність оцінку N, отриману за стандартним методом моментів.
   
Хоча ми і маємо теорему про те, що оцінки N та p не можуть бути незміщенними, але вона виконується
лише при невідомих обох параметрах. При відомому N, оцінка для p з ММП є незміщенною.

Але це не наша ситуація, тому перевіримо на асимптотичну незміщенність оцінки:

$$
    N^* = \frac{\overline{\xi}^2}{\overline{\xi} - \mathbb{D}^{***}\xi}
$$
$$
    p^* =  \frac{\overline{\xi}}{N^*}  
$$

Дослідження двох невідомих параметрів гіпотетичного закону розподілу, отримані оцінки яких пов'язані
одна з одною, є досить проблематичним. Цьому питанню можна присвятити цілу наукову статтю.
Том у в подільшому дослідженні спочатку зробимо припущення, що параметр $N$ відомий, і будемо
досліджувати оцінку параметра $p$. Після цього дослідимо оцінку параметра $N$, припустивши що
параметр $р$ відомий.
$$
N^* = \frac{\overline\xi}{p}
$$
$$
p^* = \frac{\overline\xi}{N}
$$

Перевіримо на незміщенність ці параметри:

$$
\mathbb{E}N^* =\mathbb{E} \frac{\overline\xi}{p} =\frac{\mathbb{E}\overline\xi}{p} = \frac{Np}{p} =
N
$$

$$
\mathbb{E}p^* =\mathbb{E} \frac{\overline\xi}{N} =\frac{\mathbb{E}\overline\xi}{N} = \frac{Np}{N} =
p
$$
\paragraph{Конснистентність}

$$
N^* = \frac{\overline\xi_i}{p} \xrightarrow{n\rightarrow\inf} \frac{Np}{p} = N
$$


$$
p^* = \frac{\overline\xi_i}{N} \xrightarrow{n\rightarrow\inf} \frac{Np}{N} = p
$$

Отже, обидва параметри є консистентними.
\paragraph{Ефективність}
Використаємо наслідок з критерію Рао-Крамера. 

$$
\frac{\partial \mathcal{L}}{\partial p} = C(p) (p^* - p)
$$

$$
\frac{1}{p}\sum x_k - \frac{1}{1-p} \left(nN - \sum x_k\right) = C(p) \left(\frac{\sum x_k}{nN} -
p\right)
$$

$$
\sum x_k \left( \frac{1}{p} + \frac{1}{1-p}  \right) - \frac{nN}{1-p} = C(p) \left(\frac{ \sum x_k -
nNp}{nN} \right)
$$

$$
\frac{\sum x_k - nNp}{p(1-p)} = C(p) \frac{\sum x_k - nNp}{nN}
$$

$$
C(p) = \frac{nN}{p(1-p)}
$$

Отже бачимо, що $C(p)$ не залежить від значення реалізації вибірки. Отже оцінка для p є
ефективною.\\

Оцінку для N ми перевірити не можемо через те, що не можемо взяти похідну по N.



\subsection{Довірчі інтервали}
Побудуємо довірчий інтервал для даних оцінок. Знаємо, що

Для p можемо знайти довірчий інтервал як 

$$
\mathbb{P} \left\{\frac{ | p^* - p | \sqrt{n} } {\sqrt{pq}} < t_\gamma \right\} \geq \gamma
$$

Для значення $\gamma=0.95$ $t_\gamma = 1.96$  

Розглянемо квадрат значення під ймовірнісною мірою.
$$
\frac{ ( p^* - p)^2  n } {pq} < t_\gamma^2
$$

$$
\left(1 + \frac{t_\gamma^2}{n} \right) p^2 - \left( 2 p^* + \frac{t_\gamma^2}{n}\right) p + (p^*)^2
\leq 0
$$

$$
1.43p^2 - 1.07p + 0.1024 \leq 0
$$

Отримали
$$
p \in \left(0.113, 0.636  \right)
$$

Для розрахунку довірчого інтервалу для N маємо наступну характеристику:

$$
N^* = \frac{\overline\xi}{p} \left< \textrm{Приймемо } p \textrm{ за відоме нам значення} \right>
$$

тоді ми можемо порахувати дисперсію $N^*$:
$$
\mathbb{D}N^* = \frac{ \mathbb{D}\xi}{pn^2} = \frac{ Npq}{np} = \frac{Nq}{n}
$$

Звідси 

$$
\mathbb{P} \left\{ -t_\gamma < \frac{N^* - N}{\sqrt{\mathbb{D}N^*}} < t_\gamma \right\} \geq \gamma 
$$

$$
\frac{(N^* - N)^2}{\mathbb{D}N^*} < t_\gamma^2  
$$
$$
(N^* - N)^2 \leq \frac{t_\gamma^2 N(1-p)}{n}
$$
$$
N^2 - 2N N^* + (N^*)^2 \leq \frac{t_\gamma^2 N(1-p)}{n}
$$

Для значення $\gamma=0.95$ $t_\gamma = 1.96$  

$$
N^2 - N \left( 2N^* + \frac{t_\gamma^2(1-p)}{n} \right) + (N^*)^2 < 0
$$
$$
N^2 - 18.026N + 81 = 0
$$
Отримали
\[
    N \in \left( 8.529, 9.497\right) 
\]

\subsection{Критерій про розподіл}
Перевіримо, наступну гіпотезу:
$$
H_0= \{\xi \sim Bin(9, 0.32)\}
$$

Побудуємо таблицю для $\chi^2$ критерію
\begin{center}
\begin{tabular}{|c||m{2cm}|m{2cm}|m{2cm}|m{2cm}|}
    \hline
    Елементи & $n_i$ & $np_i$ & $n_i - np_i$ & $\frac{(n_i - np_i)^2}{np_i}$ \\
    \hline
    \hline
    0 & 3 & 2 & 1 & 0.5 \\
    \hline
    1 & 10 & 10 & 0 & 0 \\
    \hline
    2 & 20 & 22 & -2 & 0.18 \\
    \hline
    3 & 33 & 27 & 5 & 0.9 \\
    \hline
    4 & 17 & 21 & -4 & 0.76 \\
    \hline
    5 & 11 & 11 & 0 & 0 \\
    \hline
    6 & 5  & 4  & 1 & 0.25 \\
    \hline
    7 & 1  & 1  & 0 & 0 \\
    \hline
    $[8, \infty)$ & 0 & 2 & -2 & 2 \\
    \hline
\end{tabular}
\end{center}
Бачимо що не для всіх значень виконується $np_i > 10$, тому об'єднаємо деякі діапазони:
\begin{center}
\begin{tabular}{|c||m{2cm}|m{2cm}|m{2cm}|m{2cm}|}
    \hline
    Елементи & $n_i$ & $np_i$ & $n_i - np_i$ & $\frac{(n_i - np_i)^2}{np_i}$ \\
    \hline
    \hline
    $[0,2)$ & 13 & 12 & 1 & 0.08 \\
    \hline
    $[2, 3)$ & 20 & 22 & -2 & 0.18 \\
    \hline
    $[3, 4)$ & 33 & 27 & 5 & 0.9 \\
    \hline
    $[4, 5)$ & 17 & 21 & -4 & 0.76 \\
    \hline
    $[5,\infty)$  & 17 & 18 & -1 & 0.05 \\
    \hline
\end{tabular}
\end{center}
тоді маємо наступне значення:
$$
\chi^2(n)=\sum_{0=1}^{8} \frac{(n_i - np_i)^2}{np_i} = 1.97
$$
A
$$
\chi_{critcal, 2, \alpha=0.95}^2 = 7.38 
$$

Так як наша область правостороння, то, ми не відхилюємо гіпотезу $H_0$.
\subsection{Висновки}
У даній роботі ми дослідили реалізацію вибірки із 100 чисел. Було перевірено, що наші дані не
суперечать тому, що дана ГС є
біноміально розподіленою та знайдено точкові та інтервальні параметри даної ГС. Була наведена
теорема, яка показує, що при обох параметрах N та p невідомі, то не існує незміщеної оцінки для цих
параметрів.
Було перевірено значення N та p на незміщеність, консистентність та ефективність (при умові що ми
знаємо інший параметр).\\

Окрім того були показані приклади інших оцінок параметра N, які можуть дати меншу зміщенність, аніж
стандартний метод моментів.
\begin{thebibliography}{9}
    \bibitem{dasgupta}
        A. DasGupta, Herman Rubin \textit{Estimation of binomial parameters when both n, p are
        unknown}
    \bibitem{carroll}
        R. J. Carroll, F. Lombard \textit{A note on N estimators for the binomial distribution}
\end{thebibliography}

\end{document}
